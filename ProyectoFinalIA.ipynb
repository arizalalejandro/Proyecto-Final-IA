{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProyectoFinalIA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDOVfBusAqy7rT1pRWJLe4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arizalalejandro/Proyecto-Final-IA/blob/main/ProyectoFinalIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "nriDFyz3yzE9",
        "outputId": "dd74f95d-a1ff-47ad-c373-65a6d31deb76"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5158af1c-a226-4005-83db-2f839568faa0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5158af1c-a226-4005-83db-2f839568faa0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Social_Network_Ads.csv to Social_Network_Ads.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Social_Network_Ads.csv': b'User ID,Gender,Age,EstimatedSalary,Purchased\\r\\n15624510,Male,19,19000,0\\r\\n15810944,Male,35,20000,0\\r\\n15668575,Female,26,43000,0\\r\\n15603246,Female,27,57000,0\\r\\n15804002,Male,19,76000,0\\r\\n15728773,Male,27,58000,0\\r\\n15598044,Female,27,84000,0\\r\\n15694829,Female,32,150000,1\\r\\n15600575,Male,25,33000,0\\r\\n15727311,Female,35,65000,0\\r\\n15570769,Female,26,80000,0\\r\\n15606274,Female,26,52000,0\\r\\n15746139,Male,20,86000,0\\r\\n15704987,Male,32,18000,0\\r\\n15628972,Male,18,82000,0\\r\\n15697686,Male,29,80000,0\\r\\n15733883,Male,47,25000,1\\r\\n15617482,Male,45,26000,1\\r\\n15704583,Male,46,28000,1\\r\\n15621083,Female,48,29000,1\\r\\n15649487,Male,45,22000,1\\r\\n15736760,Female,47,49000,1\\r\\n15714658,Male,48,41000,1\\r\\n15599081,Female,45,22000,1\\r\\n15705113,Male,46,23000,1\\r\\n15631159,Male,47,20000,1\\r\\n15792818,Male,49,28000,1\\r\\n15633531,Female,47,30000,1\\r\\n15744529,Male,29,43000,0\\r\\n15669656,Male,31,18000,0\\r\\n15581198,Male,31,74000,0\\r\\n15729054,Female,27,137000,1\\r\\n15573452,Female,21,16000,0\\r\\n15776733,Female,28,44000,0\\r\\n15724858,Male,27,90000,0\\r\\n15713144,Male,35,27000,0\\r\\n15690188,Female,33,28000,0\\r\\n15689425,Male,30,49000,0\\r\\n15671766,Female,26,72000,0\\r\\n15782806,Female,27,31000,0\\r\\n15764419,Female,27,17000,0\\r\\n15591915,Female,33,51000,0\\r\\n15772798,Male,35,108000,0\\r\\n15792008,Male,30,15000,0\\r\\n15715541,Female,28,84000,0\\r\\n15639277,Male,23,20000,0\\r\\n15798850,Male,25,79000,0\\r\\n15776348,Female,27,54000,0\\r\\n15727696,Male,30,135000,1\\r\\n15793813,Female,31,89000,0\\r\\n15694395,Female,24,32000,0\\r\\n15764195,Female,18,44000,0\\r\\n15744919,Female,29,83000,0\\r\\n15671655,Female,35,23000,0\\r\\n15654901,Female,27,58000,0\\r\\n15649136,Female,24,55000,0\\r\\n15775562,Female,23,48000,0\\r\\n15807481,Male,28,79000,0\\r\\n15642885,Male,22,18000,0\\r\\n15789109,Female,32,117000,0\\r\\n15814004,Male,27,20000,0\\r\\n15673619,Male,25,87000,0\\r\\n15595135,Female,23,66000,0\\r\\n15583681,Male,32,120000,1\\r\\n15605000,Female,59,83000,0\\r\\n15718071,Male,24,58000,0\\r\\n15679760,Male,24,19000,0\\r\\n15654574,Female,23,82000,0\\r\\n15577178,Female,22,63000,0\\r\\n15595324,Female,31,68000,0\\r\\n15756932,Male,25,80000,0\\r\\n15726358,Female,24,27000,0\\r\\n15595228,Female,20,23000,0\\r\\n15782530,Female,33,113000,0\\r\\n15592877,Male,32,18000,0\\r\\n15651983,Male,34,112000,1\\r\\n15746737,Male,18,52000,0\\r\\n15774179,Female,22,27000,0\\r\\n15667265,Female,28,87000,0\\r\\n15655123,Female,26,17000,0\\r\\n15595917,Male,30,80000,0\\r\\n15668385,Male,39,42000,0\\r\\n15709476,Male,20,49000,0\\r\\n15711218,Male,35,88000,0\\r\\n15798659,Female,30,62000,0\\r\\n15663939,Female,31,118000,1\\r\\n15694946,Male,24,55000,0\\r\\n15631912,Female,28,85000,0\\r\\n15768816,Male,26,81000,0\\r\\n15682268,Male,35,50000,0\\r\\n15684801,Male,22,81000,0\\r\\n15636428,Female,30,116000,0\\r\\n15809823,Male,26,15000,0\\r\\n15699284,Female,29,28000,0\\r\\n15786993,Female,29,83000,0\\r\\n15709441,Female,35,44000,0\\r\\n15710257,Female,35,25000,0\\r\\n15582492,Male,28,123000,1\\r\\n15575694,Male,35,73000,0\\r\\n15756820,Female,28,37000,0\\r\\n15766289,Male,27,88000,0\\r\\n15593014,Male,28,59000,0\\r\\n15584545,Female,32,86000,0\\r\\n15675949,Female,33,149000,1\\r\\n15672091,Female,19,21000,0\\r\\n15801658,Male,21,72000,0\\r\\n15706185,Female,26,35000,0\\r\\n15789863,Male,27,89000,0\\r\\n15720943,Male,26,86000,0\\r\\n15697997,Female,38,80000,0\\r\\n15665416,Female,39,71000,0\\r\\n15660200,Female,37,71000,0\\r\\n15619653,Male,38,61000,0\\r\\n15773447,Male,37,55000,0\\r\\n15739160,Male,42,80000,0\\r\\n15689237,Male,40,57000,0\\r\\n15679297,Male,35,75000,0\\r\\n15591433,Male,36,52000,0\\r\\n15642725,Male,40,59000,0\\r\\n15701962,Male,41,59000,0\\r\\n15811613,Female,36,75000,0\\r\\n15741049,Male,37,72000,0\\r\\n15724423,Female,40,75000,0\\r\\n15574305,Male,35,53000,0\\r\\n15678168,Female,41,51000,0\\r\\n15697020,Female,39,61000,0\\r\\n15610801,Male,42,65000,0\\r\\n15745232,Male,26,32000,0\\r\\n15722758,Male,30,17000,0\\r\\n15792102,Female,26,84000,0\\r\\n15675185,Male,31,58000,0\\r\\n15801247,Male,33,31000,0\\r\\n15725660,Male,30,87000,0\\r\\n15638963,Female,21,68000,0\\r\\n15800061,Female,28,55000,0\\r\\n15578006,Male,23,63000,0\\r\\n15668504,Female,20,82000,0\\r\\n15687491,Male,30,107000,1\\r\\n15610403,Female,28,59000,0\\r\\n15741094,Male,19,25000,0\\r\\n15807909,Male,19,85000,0\\r\\n15666141,Female,18,68000,0\\r\\n15617134,Male,35,59000,0\\r\\n15783029,Male,30,89000,0\\r\\n15622833,Female,34,25000,0\\r\\n15746422,Female,24,89000,0\\r\\n15750839,Female,27,96000,1\\r\\n15749130,Female,41,30000,0\\r\\n15779862,Male,29,61000,0\\r\\n15767871,Male,20,74000,0\\r\\n15679651,Female,26,15000,0\\r\\n15576219,Male,41,45000,0\\r\\n15699247,Male,31,76000,0\\r\\n15619087,Female,36,50000,0\\r\\n15605327,Male,40,47000,0\\r\\n15610140,Female,31,15000,0\\r\\n15791174,Male,46,59000,0\\r\\n15602373,Male,29,75000,0\\r\\n15762605,Male,26,30000,0\\r\\n15598840,Female,32,135000,1\\r\\n15744279,Male,32,100000,1\\r\\n15670619,Male,25,90000,0\\r\\n15599533,Female,37,33000,0\\r\\n15757837,Male,35,38000,0\\r\\n15697574,Female,33,69000,0\\r\\n15578738,Female,18,86000,0\\r\\n15762228,Female,22,55000,0\\r\\n15614827,Female,35,71000,0\\r\\n15789815,Male,29,148000,1\\r\\n15579781,Female,29,47000,0\\r\\n15587013,Male,21,88000,0\\r\\n15570932,Male,34,115000,0\\r\\n15794661,Female,26,118000,0\\r\\n15581654,Female,34,43000,0\\r\\n15644296,Female,34,72000,0\\r\\n15614420,Female,23,28000,0\\r\\n15609653,Female,35,47000,0\\r\\n15594577,Male,25,22000,0\\r\\n15584114,Male,24,23000,0\\r\\n15673367,Female,31,34000,0\\r\\n15685576,Male,26,16000,0\\r\\n15774727,Female,31,71000,0\\r\\n15694288,Female,32,117000,1\\r\\n15603319,Male,33,43000,0\\r\\n15759066,Female,33,60000,0\\r\\n15814816,Male,31,66000,0\\r\\n15724402,Female,20,82000,0\\r\\n15571059,Female,33,41000,0\\r\\n15674206,Male,35,72000,0\\r\\n15715160,Male,28,32000,0\\r\\n15730448,Male,24,84000,0\\r\\n15662067,Female,19,26000,0\\r\\n15779581,Male,29,43000,0\\r\\n15662901,Male,19,70000,0\\r\\n15689751,Male,28,89000,0\\r\\n15667742,Male,34,43000,0\\r\\n15738448,Female,30,79000,0\\r\\n15680243,Female,20,36000,0\\r\\n15745083,Male,26,80000,0\\r\\n15708228,Male,35,22000,0\\r\\n15628523,Male,35,39000,0\\r\\n15708196,Male,49,74000,0\\r\\n15735549,Female,39,134000,1\\r\\n15809347,Female,41,71000,0\\r\\n15660866,Female,58,101000,1\\r\\n15766609,Female,47,47000,0\\r\\n15654230,Female,55,130000,1\\r\\n15794566,Female,52,114000,0\\r\\n15800890,Female,40,142000,1\\r\\n15697424,Female,46,22000,0\\r\\n15724536,Female,48,96000,1\\r\\n15735878,Male,52,150000,1\\r\\n15707596,Female,59,42000,0\\r\\n15657163,Male,35,58000,0\\r\\n15622478,Male,47,43000,0\\r\\n15779529,Female,60,108000,1\\r\\n15636023,Male,49,65000,0\\r\\n15582066,Male,40,78000,0\\r\\n15666675,Female,46,96000,0\\r\\n15732987,Male,59,143000,1\\r\\n15789432,Female,41,80000,0\\r\\n15663161,Male,35,91000,1\\r\\n15694879,Male,37,144000,1\\r\\n15593715,Male,60,102000,1\\r\\n15575002,Female,35,60000,0\\r\\n15622171,Male,37,53000,0\\r\\n15795224,Female,36,126000,1\\r\\n15685346,Male,56,133000,1\\r\\n15691808,Female,40,72000,0\\r\\n15721007,Female,42,80000,1\\r\\n15794253,Female,35,147000,1\\r\\n15694453,Male,39,42000,0\\r\\n15813113,Male,40,107000,1\\r\\n15614187,Male,49,86000,1\\r\\n15619407,Female,38,112000,0\\r\\n15646227,Male,46,79000,1\\r\\n15660541,Male,40,57000,0\\r\\n15753874,Female,37,80000,0\\r\\n15617877,Female,46,82000,0\\r\\n15772073,Female,53,143000,1\\r\\n15701537,Male,42,149000,1\\r\\n15736228,Male,38,59000,0\\r\\n15780572,Female,50,88000,1\\r\\n15769596,Female,56,104000,1\\r\\n15586996,Female,41,72000,0\\r\\n15722061,Female,51,146000,1\\r\\n15638003,Female,35,50000,0\\r\\n15775590,Female,57,122000,1\\r\\n15730688,Male,41,52000,0\\r\\n15753102,Female,35,97000,1\\r\\n15810075,Female,44,39000,0\\r\\n15723373,Male,37,52000,0\\r\\n15795298,Female,48,134000,1\\r\\n15584320,Female,37,146000,1\\r\\n15724161,Female,50,44000,0\\r\\n15750056,Female,52,90000,1\\r\\n15609637,Female,41,72000,0\\r\\n15794493,Male,40,57000,0\\r\\n15569641,Female,58,95000,1\\r\\n15815236,Female,45,131000,1\\r\\n15811177,Female,35,77000,0\\r\\n15680587,Male,36,144000,1\\r\\n15672821,Female,55,125000,1\\r\\n15767681,Female,35,72000,0\\r\\n15600379,Male,48,90000,1\\r\\n15801336,Female,42,108000,1\\r\\n15721592,Male,40,75000,0\\r\\n15581282,Male,37,74000,0\\r\\n15746203,Female,47,144000,1\\r\\n15583137,Male,40,61000,0\\r\\n15680752,Female,43,133000,0\\r\\n15688172,Female,59,76000,1\\r\\n15791373,Male,60,42000,1\\r\\n15589449,Male,39,106000,1\\r\\n15692819,Female,57,26000,1\\r\\n15727467,Male,57,74000,1\\r\\n15734312,Male,38,71000,0\\r\\n15764604,Male,49,88000,1\\r\\n15613014,Female,52,38000,1\\r\\n15759684,Female,50,36000,1\\r\\n15609669,Female,59,88000,1\\r\\n15685536,Male,35,61000,0\\r\\n15750447,Male,37,70000,1\\r\\n15663249,Female,52,21000,1\\r\\n15638646,Male,48,141000,0\\r\\n15734161,Female,37,93000,1\\r\\n15631070,Female,37,62000,0\\r\\n15761950,Female,48,138000,1\\r\\n15649668,Male,41,79000,0\\r\\n15713912,Female,37,78000,1\\r\\n15586757,Male,39,134000,1\\r\\n15596522,Male,49,89000,1\\r\\n15625395,Male,55,39000,1\\r\\n15760570,Male,37,77000,0\\r\\n15566689,Female,35,57000,0\\r\\n15725794,Female,36,63000,0\\r\\n15673539,Male,42,73000,1\\r\\n15705298,Female,43,112000,1\\r\\n15675791,Male,45,79000,0\\r\\n15747043,Male,46,117000,1\\r\\n15736397,Female,58,38000,1\\r\\n15678201,Male,48,74000,1\\r\\n15720745,Female,37,137000,1\\r\\n15637593,Male,37,79000,1\\r\\n15598070,Female,40,60000,0\\r\\n15787550,Male,42,54000,0\\r\\n15603942,Female,51,134000,0\\r\\n15733973,Female,47,113000,1\\r\\n15596761,Male,36,125000,1\\r\\n15652400,Female,38,50000,0\\r\\n15717893,Female,42,70000,0\\r\\n15622585,Male,39,96000,1\\r\\n15733964,Female,38,50000,0\\r\\n15753861,Female,49,141000,1\\r\\n15747097,Female,39,79000,0\\r\\n15594762,Female,39,75000,1\\r\\n15667417,Female,54,104000,1\\r\\n15684861,Male,35,55000,0\\r\\n15742204,Male,45,32000,1\\r\\n15623502,Male,36,60000,0\\r\\n15774872,Female,52,138000,1\\r\\n15611191,Female,53,82000,1\\r\\n15674331,Male,41,52000,0\\r\\n15619465,Female,48,30000,1\\r\\n15575247,Female,48,131000,1\\r\\n15695679,Female,41,60000,0\\r\\n15713463,Male,41,72000,0\\r\\n15785170,Female,42,75000,0\\r\\n15796351,Male,36,118000,1\\r\\n15639576,Female,47,107000,1\\r\\n15693264,Male,38,51000,0\\r\\n15589715,Female,48,119000,1\\r\\n15769902,Male,42,65000,0\\r\\n15587177,Male,40,65000,0\\r\\n15814553,Male,57,60000,1\\r\\n15601550,Female,36,54000,0\\r\\n15664907,Male,58,144000,1\\r\\n15612465,Male,35,79000,0\\r\\n15810800,Female,38,55000,0\\r\\n15665760,Male,39,122000,1\\r\\n15588080,Female,53,104000,1\\r\\n15776844,Male,35,75000,0\\r\\n15717560,Female,38,65000,0\\r\\n15629739,Female,47,51000,1\\r\\n15729908,Male,47,105000,1\\r\\n15716781,Female,41,63000,0\\r\\n15646936,Male,53,72000,1\\r\\n15768151,Female,54,108000,1\\r\\n15579212,Male,39,77000,0\\r\\n15721835,Male,38,61000,0\\r\\n15800515,Female,38,113000,1\\r\\n15591279,Male,37,75000,0\\r\\n15587419,Female,42,90000,1\\r\\n15750335,Female,37,57000,0\\r\\n15699619,Male,36,99000,1\\r\\n15606472,Male,60,34000,1\\r\\n15778368,Male,54,70000,1\\r\\n15671387,Female,41,72000,0\\r\\n15573926,Male,40,71000,1\\r\\n15709183,Male,42,54000,0\\r\\n15577514,Male,43,129000,1\\r\\n15778830,Female,53,34000,1\\r\\n15768072,Female,47,50000,1\\r\\n15768293,Female,42,79000,0\\r\\n15654456,Male,42,104000,1\\r\\n15807525,Female,59,29000,1\\r\\n15574372,Female,58,47000,1\\r\\n15671249,Male,46,88000,1\\r\\n15779744,Male,38,71000,0\\r\\n15624755,Female,54,26000,1\\r\\n15611430,Female,60,46000,1\\r\\n15774744,Male,60,83000,1\\r\\n15629885,Female,39,73000,0\\r\\n15708791,Male,59,130000,1\\r\\n15793890,Female,37,80000,0\\r\\n15646091,Female,46,32000,1\\r\\n15596984,Female,46,74000,0\\r\\n15800215,Female,42,53000,0\\r\\n15577806,Male,41,87000,1\\r\\n15749381,Female,58,23000,1\\r\\n15683758,Male,42,64000,0\\r\\n15670615,Male,48,33000,1\\r\\n15715622,Female,44,139000,1\\r\\n15707634,Male,49,28000,1\\r\\n15806901,Female,57,33000,1\\r\\n15775335,Male,56,60000,1\\r\\n15724150,Female,49,39000,1\\r\\n15627220,Male,39,71000,0\\r\\n15672330,Male,47,34000,1\\r\\n15668521,Female,48,35000,1\\r\\n15807837,Male,48,33000,1\\r\\n15592570,Male,47,23000,1\\r\\n15748589,Female,45,45000,1\\r\\n15635893,Male,60,42000,1\\r\\n15757632,Female,39,59000,0\\r\\n15691863,Female,46,41000,1\\r\\n15706071,Male,51,23000,1\\r\\n15654296,Female,50,20000,1\\r\\n15755018,Male,36,33000,0\\r\\n15594041,Female,49,36000,1'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jqjrRnWzBSm"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI5duujKzCyr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Correccion de los datos\n",
        "\n",
        "Ads = pd.read_csv(\"Social_Network_Ads.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVsWoQuwzPM5"
      },
      "source": [
        "## Caracterisiticas \n",
        "\n",
        "ID = Ads['User ID']\n",
        "\n",
        "Gender = Ads['Gender'].str.upper()\n",
        "\n",
        "Genders= Gender.drop_duplicates().tolist()\n",
        "j=0\n",
        "for x in Genders:\n",
        "    Gender=Gender.replace(x,j)\n",
        "    j+=1\n",
        "\n",
        "Age = Ads['Age']\n",
        "\n",
        "Salary = Ads['EstimatedSalary']\n",
        "\n",
        "Clases = Ads['Purchased']\n",
        "## Se guardan los datos limpios \n",
        "Ads_limpio = pd.concat([ID,Gender,Age,Salary,Clases],axis=1)\n",
        "Ads_limpio.to_csv('Stars_clean.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcUz0TAfzZFy"
      },
      "source": [
        "## Seleccion datos entrenamiento\n",
        "X    = Ads_limpio.iloc[:,:-1].values\n",
        "y    = Ads_limpio.iloc[:,-1].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSi3vSfxzc35"
      },
      "source": [
        "# Normalizacion \n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test  = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrQjgtDKzf72",
        "outputId": "eb00dfb4-ec04-405c-fe22-5e8ecca3c969"
      },
      "source": [
        "## PCA\n",
        "\n",
        "pca=PCA(n_components=3)\n",
        "pca.fit(X_train) ## se realiza el entrenamiento de datos\n",
        "X_pca=pca.transform(X_train) ## se genera la transformacion de datos reduciendo a 3 componentes\n",
        "X_pca_test=pca.transform(X_test)\n",
        "expl =pca.explained_variance_ratio_\n",
        "mat_cov= pca.get_covariance()\n",
        "print('\\n')\n",
        "print(\"Matriz covarianza\",expl)\n",
        "print('suma:',sum(expl[0:5]))\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Matriz covarianza [0.30129372 0.26352067 0.23388952]\n",
            "suma: 0.7987039105268429\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st2BKTRAzkJO",
        "outputId": "74d28dd1-0013-4ca2-83e9-4f30a639999e"
      },
      "source": [
        "## Entrenamiento con regresion logistica\n",
        "\n",
        "Bias=np.ones((len(X_train),1))\n",
        "Bias_test= np.ones((len(X_test),1))\n",
        "X_train = np.hstack((X_train,Bias))\n",
        "X_test  = np.hstack((X_test,Bias_test))\n",
        "regresion = LogisticRegression(random_state=100, solver='liblinear', max_iter=100000000).fit(X_train,y_train)\n",
        "y_predict=regresion.predict(X_test)\n",
        "MCC_r=matthews_corrcoef(y_test,y_predict)\n",
        "F1_r=f1_score(y_test,y_predict,average='micro')\n",
        "print(\"hipotesis X+1, el MCC es: \", MCC_r)\n",
        "print(\"hipotesis X+1, el F1 es: \", F1_r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hipotesis X+1, el MCC es:  0.7746113346928807\n",
            "hipotesis X+1, el F1 es:  0.9125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUxkURggzolk",
        "outputId": "740c76e2-fca8-4d2c-e91a-6bf30cf5a10e"
      },
      "source": [
        "## Entrenamiento con regresion logistica\n",
        "\n",
        "Bias=np.ones((len(X_train),1))\n",
        "Bias_test= np.ones((len(X_test),1))\n",
        "X_train = np.hstack((X_train,X_train**2,Bias))\n",
        "X_test  = np.hstack((X_test,X_test**2,Bias_test))\n",
        "regresion = LogisticRegression(random_state=100, solver='liblinear', max_iter=100000000).fit(X_train,y_train)\n",
        "y_predict=regresion.predict(X_test)\n",
        "MCC_r=matthews_corrcoef(y_test,y_predict)\n",
        "F1_r=f1_score(y_test,y_predict,average='micro')\n",
        "print(\"hipotesis X+X^2+1, el MCC es: \", MCC_r)\n",
        "print(\"hipotesis X+X^2+1, el F1 es: \", F1_r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hipotesis X+X^2+1, el MCC es:  0.8746081504702194\n",
            "hipotesis X+X^2+1, el F1 es:  0.9500000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JomYIu-zupJ",
        "outputId": "91f796d7-e307-44c1-aba5-3c8316cb9433"
      },
      "source": [
        "## Entrenamiento con regresion logistica diferente hipotesis\n",
        "\n",
        "Bias=np.ones((len(X_train),1))\n",
        "Bias_test= np.ones((len(X_test),1))\n",
        "X_train = np.hstack((X_train,X_train**2,X_train**3,Bias))\n",
        "X_test  = np.hstack((X_test,X_test**2,X_test**3,Bias_test))\n",
        "regresion = LogisticRegression(random_state=100, solver='liblinear', max_iter=100000000).fit(X_train,y_train)\n",
        "y_predict=regresion.predict(X_test)\n",
        "MCC_r=matthews_corrcoef(y_test,y_predict)\n",
        "F1_r=f1_score(y_test,y_predict,average='micro')\n",
        "print(\"hipotesis X+X^3+1, el MCC es: \", MCC_r)\n",
        "print(\"hipotesis X+X^3+1, el F1 es: \", F1_r)\n",
        "\n",
        "\n",
        "print(\"El mejor resultado es con la tercera hipotesis\")\n",
        "print(classification_report(y_test, y_predict))\n",
        "\n",
        "\n",
        "#********************************************************************************#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hipotesis X+X^3+1, el MCC es:  0.8796856499979752\n",
            "hipotesis X+X^3+1, el F1 es:  0.9500000000000001\n",
            "El mejor resultado es con la tercera hipotesis\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96        58\n",
            "           1       0.88      0.95      0.91        22\n",
            "\n",
            "    accuracy                           0.95        80\n",
            "   macro avg       0.93      0.95      0.94        80\n",
            "weighted avg       0.95      0.95      0.95        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlSVfU9wz2ru",
        "outputId": "0d0c1857-adb9-495a-b40a-e902b184446b"
      },
      "source": [
        "Bias=np.ones((len(X_pca),1))\n",
        "Bias_test= np.ones((len(X_pca_test),1))\n",
        "X_train = np.hstack((X_pca,X_pca**2,X_pca**3,Bias))\n",
        "X_test  = np.hstack((X_pca_test,X_pca_test**2,X_pca_test**3,Bias_test))\n",
        "regresion = LogisticRegression(random_state=100, solver='liblinear', max_iter=100000000).fit(X_pca,y_train)\n",
        "y_predict=regresion.predict(X_pca_test)\n",
        "MCC_r=matthews_corrcoef(y_test,y_predict)\n",
        "F1_r=f1_score(y_test,y_predict,average='micro')\n",
        "print(\"hipotesis X+X^3+1 y PCA, el MCC es: \", MCC_r)\n",
        "print(\"hipotesis X+X^3+1 y PCA, el F1 es: \", F1_r)\n",
        "\n",
        "\n",
        "#********************************************************************************#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hipotesis X+X^3+1 y PCA, el MCC es:  0.7750114611687802\n",
            "hipotesis X+X^3+1 y PCA, el F1 es:  0.9125\n"
          ]
        }
      ]
    }
  ]
}